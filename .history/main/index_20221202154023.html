<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Dance2MIDI: Dance-Driven Milti-Instruments Music Generation</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="./assets/css/styles.css">

    <meta property="og:site_name" content="Dance2MIDI: Dance-Driven Milti-Instruments Music Generation" />
    <meta property="og:type" content="video.other" />
    <meta property="og:title" content="Dance2MIDI: Dance-Driven Milti-Instruments Music Generation" />
    <meta property="og:description" content="Dance2MIDI: Dance-Driven Milti-Instruments Music Generation, 2022." />
    <meta property="og:url" content="https://dance2midi.github.io/" />

    <meta property="article:publisher" content="https://dance2midi.github.io/" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Dance2MIDI: Dance-Driven Milti-Instruments Music Generation" />
    <meta name="twitter:url" content="https://dance2midi.github.io/" />

    <script type="module" src="https://unpkg.com/@google/model-viewer@2.0.1/dist/model-viewer.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.js?features=IntersectionObserver"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"></script>
    <script src="./assets/scripts/main.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/sticksy/dist/sticksy.min.js"></script>
</head>

<body class="noscroll">
    <div id="set-height">
        <div class="js-sticky-widget">
            <canvas id="v0"></canvas>
        </div>
    </div>
    <div id="mouse_div">
        <div class="mouse_scroll">
            <div class="mouse">
                <div class="wheel"></div>
            </div>
            <div>
                <span class="m_scroll_arrows unu"></span>
                <span class="m_scroll_arrows doi"></span>
                <span class="m_scroll_arrows trei"></span>
            </div>
        </div>
    </div>
    <script>
        const html = document.getElementById("set-height");
        const canvas = document.getElementById("v0");
        let context = canvas.getContext("2d");
        const frameCount = 0;
        let frame_narrow = ""

        function update_narrow() {
            let w = window.innerWidth;
            if (w >= 1300) {
                frame_narrow = "";
                canvas.width = 2000;
                canvas.height = 1000;
                context = canvas.getContext("2d")
            } else if (w >= 1000) {
                frame_narrow = "_midrange";
                canvas.width = 2000;
                canvas.height = 2000;
                context = canvas.getContext("2d")
            } else {
                frame_narrow = "_narrow";
                canvas.width = 1000;
                canvas.height = 2000;
                context = canvas.getContext("2d")
            }
            Sticksy.hardRefreshAll();
        }

        function drawToCanvas() {
            const scrollTop = window.pageYOffset; //html.scrollTop;
            const maxScrollTop = html.scrollHeight; // - window.innerHeight;
            const scrollFraction = scrollTop / maxScrollTop;
            const frameIndex = Math.min(
                frameCount - 1,
                Math.ceil(scrollFraction * frameCount)
            );

            const mousefade = 1 - Math.min((scrollFraction / 0.02), 1);
            document.getElementById("mouse_div").style.opacity = mousefade;

            requestAnimationFrame(() => updateImage(frameIndex + 1))
        }

        window.addEventListener('resize', function(event) {
            update_narrow();
            drawToCanvas();
        });
        const currentFrame = index => (
            `./assets/media/frames${frame_narrow}/${(60 + 2 * (index - 1)).toString().padStart(4, '0')}.jpg`
        )

        const preloadImages = () => {
            for (let i = 1; i < frameCount; i++) {
                const img = new Image();
                img.src = currentFrame(i);
            }
        };

        let setHeight = document.getElementById("set-height");
        setHeight.style.height = frameCount * 200 + "px";

        const img = new Image()
        img.src = currentFrame(1);
        update_narrow();
        img.onload = function() {
            context.drawImage(img, 0, 0);
        }

        const updateImage = index => {
            img.src = currentFrame(index);
            context.drawImage(img, 0, 0);
        }

        window.addEventListener('scroll', () => {
            drawToCanvas();
        });

        preloadImages()
        var stickyElements = Sticksy.initializeAll('.js-sticky-widget')
    </script>
    <!-- <div style="background-color: rgb(26, 26, 26);">
        <img src="./assets/media/cover.png" class="img-fluid" alt="Responsive image">
    </div> -->

    <div class="button-bar text-light" style="padding-bottom: 10px; background-color: rgb(35, 35, 35);">
        <div class="container" style="max-width: 768px;">
            <h1 class="text-center"><b>Dance2MIDI:</b> Dance-Driven Multi-Instrument Music Generation</h1>
        </div>
        <div class="container" style="max-width: 768px; padding-bottom: 50px;">
            <div class="row authors">
                <div class="col">
                    <h5 class="text-center">Bo Han</h5>
                    <h6 style="margin-top: 10px;" class="text-center">Zhejiang University</h6>
                </div>
                <div class="col">
                    <h5 class="text-center">Yi Ren</h5>
                    <h6 style="margin-top: 10px;" class="text-center">Sea AI Lab</h6>
                </div>
            </div>
        </div>
        <div class="buttons" style="margin-bottom: 8px;">
            <a class="btn text-light" role="button">
                <svg style="width:24px;height:24px;margin-left:-12px;margin-right:12px" viewBox="0 0 24 24">
                    <path fill="white" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z"></path>
                </svg>Paper
            </a>
        </div>
    </div>
    <div style="background-color: rgb(0, 0, 0);">
        <div class="container text-light" style="max-width: 768px; padding-top: 30px; padding-bottom: 30px;">
            <div class="row">
                <div class="col-md-12">
                    <p>
                        <!-- <strong> -->
                            Previous works focus
                            on monophonic or raw audio generation, while the multi-
                            instruments scenario is under-explored. The challenges of
                            the dance-driven multi-instruments music (MIDI) generation are two-fold: 1) no publicly available multi-instruments
                            MIDI and video paired dataset and 2) the weak correlation between music and video. To tackle these challenges,
                            we build the first multi-instruments MIDI and dance paired
                            dataset (D2MIDI). Based on our proposed dataset, we introduce a multi-instruments MIDI generation framework
                            (Dance2MIDI) conditioned on dance video. Specifically, 1)
                            to model the correlation between music and dance, we encode
                            the dance motion using the GCN, and 2) to generate harmonious and coherent music, we employ Transformer to decode
                            the MIDI sequence. We evaluate the generated music of our
                            framework trained on D2MIDI dataset and demonstrate that
                            our method outperforms existing methods. We will publish
                            the dataset and code soon.
                        <!-- </strong> -->
                    </p>
                </div>
            </div>
        </div>


    </div>

    <!-- <div style="background-color: rgb(60, 60, 60);">
        <div class="container text-light" style="padding-top: 30px; padding-bottom: 30px; text-align:center;">
            <h2><strong>EDGE generates choreographies from music</strong></h2>
            <p>EDGE uses music embeddings from the powerful Jukebox model to gain a broad understanding of music and create high-quality dances even for in-the-wild music samples. (Unmute for music)</p>
        </div>
    </div> -->

    <!-- Big grid -->
    <div style="background-color: rgb(0, 0, 0);">
        <div class="video-row">
            <div class="col" style="padding:0; display:grid;">
                <video class="specialvideo video lazy img-fluid" autoplay muted loop playsinline controls>
                    <source src="./assets/resources/2_0382.mp4" type="video/mp4"></source>
                </video>
            </div>
            <div class="col" style="padding:0; display:grid;">
                <video class="specialvideo video lazy img-fluid" autoplay muted loop playsinline controls>
                    <source src="./assets/resources/id00074.mp4" type="video/mp4"></source>
                </video>
            </div>
        </div>
        <div class="video-row">
            <div class="col" style="padding:0; display:grid;">
                <video class="specialvideo video lazy img-fluid" autoplay muted loop playsinline controls>
                    <source src="./assets/resources/id00126.mp4" type="video/mp4"></source>
                </video>
            </div>
            <div class="col" style="padding:0; display:grid;">
                <video class="specialvideo video lazy img-fluid" autoplay muted loop playsinline controls>
                    <source src="./assets/resources/id00130.mp4" type="video/mp4"></source>
                </video>
            </div>
        </div>
        <div class="video-row">
            <div class="col" style="padding:0; display:grid;">
                <video class="specialvideo video lazy img-fluid" autoplay muted loop playsinline controls>
                    <source src="./assets/resources/id00450.mp4" type="video/mp4"></source>
                </video>
            </div>
            <div class="col" style="padding:0; display:grid;">
                <video class="specialvideo video lazy img-fluid" autoplay muted loop playsinline controls>
                    <source src="./assets/resources/id00456.mp4" type="video/mp4"></source>
                </video>
            </div>
        </div>
    </div>
    <div style="background-color: rgb(60, 60, 60);">
        <div class="container text-light" style="padding-top: 30px; padding-bottom: 30px; text-align:center;">
            <h2><strong>The Dance2MIDI Model, Explained</strong></h2>
        </div>
    </div>
    <div style="background-color: rgb(255, 255, 255);">
        <div class="container" style="max-width: 768px; padding-top: 30px; padding-bottom: 30px; ">
            <div class="row">
                <div class="col-md-12">
                    <img src="./assets/media/method_diagram.png" class="img-fluid" alt="Responsive image">
                </div>
            </div>
        </div>
    </div>
    <!-- <div style="background-color: rgb(230, 230, 230);">
        <div class="container text-dark" style="max-width: 768px; padding-top: 30px; padding-bottom: 30px;">
            <div class="row">
                <div class="col-md-12">
                    <h6 class="caption" style="font-size: 1.2em; text-align:center;">Pictured: Although Dance2MIDI is trained on 30-second dance clips and MIDI pieces, it can generate MIDI pieces of any length by imposing temporal constraints on batches of sequences. In the pictured example, EDGE constrains the first half of each sequence to
                        match the second half of the previous one.</h6>
                </div>
            </div>
        </div>
    </div> -->
    <div style="background-color: rgb(70, 70, 70);">
        <div class="container text-light" style="max-width: 768px; padding-top: 30px; padding-bottom: 30px;">
            <div class="row">
                <div class="col-md-12">
                    <p> It mainly consists of two components: the
                        video stream and the MIDI stream. We adopt the Transformer
                        model as the backbone network for music generation.
                        Specifically, given the human motion feature encoded from
                        the visual stream, we treat it as a condition and then predict
                        the next music event in the MIDI stream. For the key attention module, we use both the Masked
                        Self-Attention module (MSA) and the Video Guided MIDI
                        module (VGM).</p>
                </div>
            </div>
        </div>
    </div>

    <!-- <div>
        <div class="video-row width-switch">
            <div class="col" style="padding:0; display:grid;">
                <video id="rotatingvideo1" class="specialvideo video lazy img-fluid" autoplay muted loop playsinline controls>
                    <source src="./assets/media/gallery1.mp4" type="video/mp4"></source>
                </video>
                <video id="rotatingvideo2" class="hidden specialvideo video lazy img-fluid" autoplay muted loop playsinline controls>
                    <source src="./assets/media/gallery2.mp4" type="video/mp4"></source>
                </video>
                <video id="rotatingvideo3" class="hidden specialvideo video lazy img-fluid" autoplay muted loop playsinline controls>
                    <source src="./assets/media/gallery3.mp4" type="video/mp4"></source>
                </video>
                <video id="rotatingvideo4" class="hidden specialvideo video lazy img-fluid" autoplay muted loop playsinline controls>
                    <source src="./assets/media/gallery4.mp4" type="video/mp4"></source>
                </video>
                <div class="mycarouselcaption">
                    <p id="rotatingcaption1">Joint-Wise Constraint: Generate lower body from upper body</p>
                    <p id="rotatingcaption2" class="hidden">Joint-Wise Constraint: Generate upper body from lower body</p>
                    <p id="rotatingcaption3" class="hidden">Temporal Constraint: In-Betweening</p>
                    <p id="rotatingcaption4" class="hidden">Temporal Constraint: Continuation</p>
                </div>
            </div>
            <div class="col text-light align-items-center" style="background-color: rgb(35, 35, 35);">
                <div style="display:flex;  align-items: center; justify-content: center; height:100%;">
                    <div class="container width-switch-text" style="font-size: 1vw;">
                        <h1>Editable Synthesis</h1>
                        <h5>EDGE supports arbitrary spatial and temporal constraints. This can be used to support many end-user applications, including:</h5>
                        <p></p>
                        <ol>
                            <li>
                                Arbitrarily long dances, by enforcing temporal continuity between batches of multiple sequences.
                            </li>
                            <li>
                                Dances subject to joint-wise constraints, i.e. lower body generation given upper body motion, or vice versa.
                            </li>
                            <li>
                                Motion In-Betweening: Dances that start and end with prespecified motions.
                            </li>
                            <li>
                                Dance Continuation: Dances that start with a prespecified motion.
                            </li>
                            <li>
                                And many more!
                            </li>
                        </ol>
                        <button class="btn btn-outline-light" type="submit" onclick="cycleGallery();">Click to cycle gallery</button>
                    </div>

                </div>
            </div>
        </div>
    </div> -->
    <div style="background-color: rgb(230, 230, 230);">
        <div class="container my-text-dark" style="padding-top: 30px; padding-bottom: 30px; text-align:center;">
            <div clas="row">
                <div class="col">
                    <h1>The D2MIDI Dataset</h1>
                    <p>D2MIDI is the first dance-to-MIDI multi-
                        instrument dataset, which has several important features:
                        1) High-quality solo dance video: the videos are crawled
                        from the internet but are hand-picked so that some bad quality
                        videos and those with multiple dancers are filtered out. 2) Multi-instrument and polyphonic MIDI:
                        we transcribe the MIDI from the audio and obtain the time-
                        synchronized and paired multi-instrument and polyphonic
                        MIDI for each dance video. 3) Multi-style and large-scale: the dance videos cover several styles and
                        contain 6k clips.</p>
                    <!-- <video class="specialvideo video lazy img-fluid" autoplay muted loop playsinline style="width:65%">
                        <source src="./assets/media/physical.mp4" type="video/mp4"></source>
                    </video> -->
                    <audio controls>
                        <source src="./assets/wav/2_0009.wav" type="audio/mpeg">
                    </audio>
                    <!--play midi file-->
                    <embed src="./assets/midi/2_0009.mid" width="100%" height="100" controls="controls" />
                    
                </div>
            </div>

        </div>
    </div>

    <div style="background-color: rgb(70, 70, 70);">
        <div class="container text-light" style="max-width: 768px; padding: 30px 0px;">
            <div class="row">
                <div class="col-md-12">
                    <p>This website draws heavy design inspiration from the excellent <a href="https://edge-dance.github.io//">EDGE</a> site.</p>
                </div>
            </div>
        </div>
    </div>
</body>

</html>